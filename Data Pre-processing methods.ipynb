{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "rotary-omaha",
   "metadata": {},
   "source": [
    "# Data Preparation for Machine Learning\n",
    "* Rescale data\n",
    "* Standardize data\n",
    "* Normalize data\n",
    "* Binarize data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "judicial-tackle",
   "metadata": {},
   "source": [
    "## Data Transforms\n",
    "1. Fit and Multiple Transform\n",
    "2. Combined Fit-and-Transform\n",
    "\n",
    "**Fit and Multiple Transform**(prefer mostly this)\n",
    "1. we call the **fit()** function to prepare the parameters of the transform once on our data.\n",
    "2. Later we use **transform()** on same data to prepare it for modelling and again on the test or validation dataset or new data that we see in the future.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesbian-editing",
   "metadata": {},
   "source": [
    "### 1 . Rescale data\n",
    "* Attributes are often rescaled into the range between 0 and 1,this is referred to as **normalization**.\n",
    "* It is useful for algorithms like gradient descent,that weight inputs like regression and neural networks and algorithms that use **distance measures like K-Nearest Neighbors**.\n",
    "\n",
    "we can rescale our data using scikit-learn using **MinMaxScaler**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ordered-huntington",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.353 0.744 0.59  0.354 0.    0.501 0.234 0.483]\n",
      " [0.059 0.427 0.541 0.293 0.    0.396 0.117 0.167]\n",
      " [0.471 0.92  0.525 0.    0.    0.347 0.254 0.183]\n",
      " [0.059 0.447 0.541 0.232 0.111 0.419 0.038 0.   ]\n",
      " [0.    0.688 0.328 0.354 0.199 0.642 0.944 0.2  ]]\n"
     ]
    }
   ],
   "source": [
    "# Rescaling data (between 0 and 1)\n",
    "\n",
    "from pandas import read_csv\n",
    "from numpy import set_printoptions\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "filename = 'pima-indians-diabetes.data.csv'\n",
    "names = ['preg','plas','pres','skin','test','mass','pedi','age','class']\n",
    "dataframe = read_csv(filename,names=names)\n",
    "array = dataframe.values\n",
    "\n",
    "# separating array into input and output components\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "rescaledX = scaler.fit_transform(X)\n",
    "\n",
    "# summarizing transformed data\n",
    "set_printoptions(precision=3)\n",
    "print(rescaledX[0:5,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sapphire-quality",
   "metadata": {},
   "source": [
    "### 2 . Standardize data\n",
    "* It is a useful technique to transform attributes with a Gaussian distribution and differing means and standard deviation to a **standard Gaussian distribution with a mean of 0 and a standard deviation of 1**\n",
    "* It works best for algorithms like **linear regression**,**logistic regression**,**linear discriminate analysis**.\n",
    "\n",
    "we can standardize data using scikit-learn with the **StandardScaler** class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "looking-action",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.64   0.848  0.15   0.907 -0.693  0.204  0.468  1.426]\n",
      " [-0.845 -1.123 -0.161  0.531 -0.693 -0.684 -0.365 -0.191]\n",
      " [ 1.234  1.944 -0.264 -1.288 -0.693 -1.103  0.604 -0.106]\n",
      " [-0.845 -0.998 -0.161  0.155  0.123 -0.494 -0.921 -1.042]\n",
      " [-1.142  0.504 -1.505  0.907  0.766  1.41   5.485 -0.02 ]]\n"
     ]
    }
   ],
   "source": [
    "# Standardize data(0 mean, 1 stdev)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(X)\n",
    "rescaledX = scaler.transform(X)\n",
    "\n",
    "## summarizing transformed data\n",
    "set_printoptions(precision=3)\n",
    "print(rescaledX[0:5,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latin-botswana",
   "metadata": {},
   "source": [
    "### 3 . Normalize data\n",
    "* It refers to rescaling each observation(row) to have a length of 1(unit norm).\n",
    "* It can be useful for sparse datasets(lots of zeros) with attributes of varying scales when using algorithms that weight input values such as neural networks and algorithms that use distance measures such as k-Nearest Neighbors.\n",
    "\n",
    "we can normalize data in python with scikit-learn using the **Normalizer** class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "swiss-marriage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.034 0.828 0.403 0.196 0.    0.188 0.004 0.28 ]\n",
      " [0.008 0.716 0.556 0.244 0.    0.224 0.003 0.261]\n",
      " [0.04  0.924 0.323 0.    0.    0.118 0.003 0.162]\n",
      " [0.007 0.588 0.436 0.152 0.622 0.186 0.001 0.139]\n",
      " [0.    0.596 0.174 0.152 0.731 0.188 0.01  0.144]]\n"
     ]
    }
   ],
   "source": [
    "# Normalize data (length of 1)\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "normalizedX = scaler.transform(X)\n",
    "\n",
    "# summarizing transformed data\n",
    "set_printoptions(precision=3)\n",
    "print(normalizedX[0:5,:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optimum-mississippi",
   "metadata": {},
   "source": [
    "### 4 . Binarize data\n",
    "* we can transform our data using **binary threshold**.\n",
    "* All values above the **threshold** are marked **1** and all equal to or below are marked as **0**.\n",
    "* It can be useful when we have probabilities that we want to make crisp values.\n",
    "\n",
    "we can create binary attributes in python using scikit-learn with the **Binarizer** class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "vanilla-greek",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 1. 0. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 0. 1. 1. 1.]\n",
      " [1. 1. 1. 0. 0. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [0. 1. 1. 1. 1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# binarization\n",
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "# all values equal or less than 0 are marked 0 and all of those above 0 are marked 1\n",
    "binarizer = Binarizer(threshold=0.0).fit(X)\n",
    "binaryX = binarizer.transform(X)\n",
    "\n",
    "## summarizing transformed data\n",
    "set_printoptions(precision=3)\n",
    "print(binaryX[0:5,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certified-bottle",
   "metadata": {},
   "source": [
    "## Summary\n",
    "* learnt how to pre-process data using various methods depending on our requiements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stopped-bidder",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
