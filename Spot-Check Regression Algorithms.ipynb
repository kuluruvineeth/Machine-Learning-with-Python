{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sticky-principal",
   "metadata": {},
   "source": [
    "# Algorithms Overview\n",
    "\n",
    "we are going to take a look at **seven regression algorithms** that we can spot-check on our dataset.\n",
    "\n",
    "**1. Linear ML Algorithms**\n",
    "   * Linear Regression\n",
    "   * Ridge Regression\n",
    "   * LASSO Linear Regression\n",
    "   * Elastic Net Regression\n",
    "   \n",
    "**2. Nonlinear ML Algorithms**\n",
    "   * k-Nearest Neighbors\n",
    "   * Classification and Regression Trees\n",
    "   * Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developing-identification",
   "metadata": {},
   "source": [
    "## 1.1 Linear Regression\n",
    "* It assumes the input variables have a Gaussian distribution.\n",
    "* It is also assumed that input variables are relevant to the output variable and they are not highly correlated with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "gross-abraham",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-34.70525594452491\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "filename = 'housing.csv'\n",
    "names = ['CRIM','ZN','INDUS','CHAS','NOX','RM','AGE','DIS','RAD','TAX','PTRATIO','B','LSTAT','MEDV']\n",
    "dataframe = read_csv(filename,delim_whitespace=True,names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:13]\n",
    "Y = array[:,13]\n",
    "kfold = KFold(n_splits=10,random_state=None)\n",
    "model = LinearRegression()\n",
    "scoring = 'neg_mean_squared_error'\n",
    "results = cross_val_score(model,X,Y,cv=kfold,scoring=scoring)\n",
    "print(results.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "junior-robinson",
   "metadata": {},
   "source": [
    "## 1.2 Ridge Regression\n",
    "* It is an extension of linear regression where the loss function is modified to minimize the complexity of the model measured as the sum squared value of the coefficient values(L2-norm). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "honest-fountain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-34.07824620925937\n"
     ]
    }
   ],
   "source": [
    "# Ridge Regression\n",
    "from sklearn.linear_model import Ridge\n",
    "model = Ridge()\n",
    "scoring = 'neg_mean_squared_error'\n",
    "results = cross_val_score(model,X,Y,cv=kfold,scoring=scoring)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "careful-freeware",
   "metadata": {},
   "source": [
    "## 1.3 LASSO Regression\n",
    "* LASSO - **Least Absolute Shrinkage and Selection Operator**.\n",
    "* The loss function is modified to minimize the complexity of the model measured as the sum absolute value of the coefficient values(L1-norm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "marine-delay",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-34.46408458830232\n"
     ]
    }
   ],
   "source": [
    "# Lasso Regression\n",
    "from sklearn.linear_model import Lasso\n",
    "model = Lasso()\n",
    "scoring = 'neg_mean_squared_error'\n",
    "results = cross_val_score(model,X,Y,cv=kfold,scoring=scoring)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collected-sheet",
   "metadata": {},
   "source": [
    "## 1.4 ElasticNet Regression\n",
    "* It is a form of regularization regression that combines the properties of both Ridge Regression and LASSO regression.\n",
    "* It seeks to minimize the complexity of the regression model(**magnitude and number of regression coefficients**) by penalizing the model using both the L2-norm and L1-norm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dying-morris",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-31.16457371424976\n"
     ]
    }
   ],
   "source": [
    "# ElasticNet Regression\n",
    "from sklearn.linear_model import ElasticNet\n",
    "model = ElasticNet()\n",
    "scoring = 'neg_mean_squared_error'\n",
    "results = cross_val_score(model,X,Y,cv=kfold,scoring=scoring)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "correct-passenger",
   "metadata": {},
   "source": [
    "## 2.1 K-Nearest Neighbors\n",
    "* From the k neighbors, a mean or median output variable is taken as the prediction.\n",
    "* distance metric is used\n",
    "* The **Minkowski distance is used by default which is a generalization of both the Euclidean distance(used when all inputs have the same scale) and Manhattan distance (for when the scales of the input variables differ)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "hourly-luxury",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-107.28683898039215\n"
     ]
    }
   ],
   "source": [
    "## KNN Regression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "model = KNeighborsRegressor()\n",
    "scoring = 'neg_mean_squared_error'\n",
    "results = cross_val_score(model,X,Y,cv=kfold,scoring=scoring)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effective-clinic",
   "metadata": {},
   "source": [
    "## 2.2 Classification and Regression Trees \n",
    "* It uses the training data to select the best points to split the data in order to minimize a cost metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "affected-blake",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-34.269355294117645\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Regression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "model = DecisionTreeRegressor()\n",
    "scoring = 'neg_mean_squared_error'\n",
    "results = cross_val_score(model,X,Y,cv=kfold,scoring=scoring)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excellent-drove",
   "metadata": {},
   "source": [
    "## 2.3 Support Vector Machines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "hydraulic-weekend",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-72.25543311855311\n"
     ]
    }
   ],
   "source": [
    "# SVM Regression\n",
    "from sklearn.svm import SVR\n",
    "model = SVR()\n",
    "scoring = 'neg_mean_squared_error'\n",
    "results = cross_val_score(model,X,Y,cv=kfold,scoring=scoring)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demonstrated-store",
   "metadata": {},
   "source": [
    "# Summary\n",
    "* learnt how to spot-check on 7 machine learning regression algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sealed-soundtrack",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
